{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "#! -*-coding:utf-8 -*-\n",
    "\n",
    "import os\n",
    "import torch\n",
    "import time\n",
    "import numpy as np\n",
    "from tqdm.auto import trange\n",
    "\n",
    "from sde import SDE\n",
    "from utils import visualize_diffusion_process_2d, visualize_line\n",
    "from utils import weight_init\n",
    "from data import SwissRoll\n",
    "from evaluate import evaluate_2d\n",
    "\n",
    "torch.set_default_dtype(torch.float64)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "## hyper-parameters\n",
    "T = 1.0                     # the terminal time\n",
    "sample_size = 10000         # the number of random samples\n",
    "hdim = 50                   # the width of neural network\n",
    "steps = 20000               # training steps\n",
    "batch_size = 400            # size of mini-batch for training\n",
    "N = 5                       # control the number of visualizations\n",
    "\n",
    "## define data\n",
    "a = 2.0                     # control the scale of swissroll\n",
    "\n",
    "true_data = SwissRoll(noise=0.0, a=a)\n",
    "\n",
    "x0, x1 = -1.2 * a, 1.2 * a      # the range of x coordinate to visualize and compute divergences\n",
    "y0, y1 = -1.2 * a, 1.2 * a      # the range of y coordinate to visualize and compute divergences\n",
    "\n",
    "data_dim = true_data.data_dim   # dimension of swissroll (=2)\n",
    "\n",
    "## define sde model\n",
    "beta0 = 0.1                     # beta at t = 0\n",
    "beta1 = 20.0                    # beta at t = T\n",
    "\n",
    "model = SDE(T=T, beta0=beta0, beta1=beta1, sde_type=\"vp\", beta_type=\"linear\", data_dim=data_dim, hidden_dim=hdim)\n",
    "model.apply(weight_init)\n",
    "\n",
    "## create directories for saving results\n",
    "model_dir = f\"sde_swissroll_2D_T-{T:.2f}_trainsteps-{steps:d}_bs-{batch_size:d}_hdim-{hdim:d}\"\n",
    "output_dir = f\"outputs/{model_dir}\"\n",
    "ckpt_dir = f\"ckpts/{model_dir}\"\n",
    "\n",
    "if not os.path.exists(output_dir):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "\n",
    "if not os.path.exists(ckpt_dir):\n",
    "    os.makedirs(ckpt_dir, exist_ok=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize forward process"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "\n",
    "## visualize forward process\n",
    "t_unit = T / N\n",
    "t_schedule = np.arange(N + 1) * t_unit\n",
    "\n",
    "# forward process\n",
    "x_0 = true_data.sample(sample_size)\n",
    "x_0 = torch.from_numpy(x_0).view(-1, data_dim)\n",
    "\n",
    "x_t = list()\n",
    "\n",
    "for t in t_schedule:\n",
    "\n",
    "    x_t.append(model.forward_sde(x_0, t, to_numpy=True))\n",
    "\n",
    "x_t = np.stack(x_t, axis=0)\n",
    "\n",
    "visualize_diffusion_process_2d(xs=x_t, titles=[f\"t={t:.2f}\" for t in t_schedule], savename=None)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Train the score matching model"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# If model exists, load it\n",
    "if os.path.exists(os.path.join(ckpt_dir, \"sde.pth\")):\n",
    "    model.load_state_dict(torch.load(os.path.join(ckpt_dir, \"sde.pth\")))\n",
    "    print(f\"model loaded from {os.path.join(ckpt_dir, 'sde.pth')}\")\n",
    "\n",
    "# otherwise, train it\n",
    "else:\n",
    "    print(f\"begin to train\")\n",
    "    model.estimate_score(data_iter=true_data.data_iter(batch_size=batch_size, maxiter=steps), steps=steps, lr=1e-2)\n",
    "    print(f\"finish training\")\n",
    "\n",
    "    torch.save(model.state_dict(), os.path.join(ckpt_dir, \"sde.pth\"))\n",
    "    print(f\"model saved to {os.path.join(ckpt_dir, 'sde.pth')}\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Visualize the reverse process"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "reverse_N = 20000\n",
    "h_alphas = [0.0, 1.0, 2.0, 3.0, 4.0]\n",
    "\n",
    "x_T = torch.randn(sample_size, data_dim)\n",
    "\n",
    "# reverse process\n",
    "\n",
    "tilde_x_t = list()\n",
    "\n",
    "for h_alpha in h_alphas:\n",
    "        \n",
    "    tic = time.time()\n",
    "    tilde_x_t.append(model.sample(x_t=x_T, T=0.0, N=reverse_N, to_numpy=True, sf_alpha=h_alpha))\n",
    "    toc = time.time()\n",
    "\n",
    "    print(f\"sampling with alpha={h_alpha:.2f} done, cost {toc - tic:.2f}s\")\n",
    "\n",
    "tilde_x_t = np.stack(tilde_x_t, axis=0)\n",
    "\n",
    "visualize_diffusion_process_2d(xs=tilde_x_t, titles=[f\"h={h:.2f}\" for h in h_alphas], savename=None)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Evaluate"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "data = list()\n",
    "\n",
    "for h in np.linspace(start=0.0, stop=h_alphas[-1], num=21, endpoint=True)[::-1]:\n",
    "# for sa in [sf_alpha]:\n",
    "\n",
    "    x_0 = true_data.sample(sample_size)\n",
    "    x_0 = torch.from_numpy(x_0).view(-1, data_dim)\n",
    "    \n",
    "    x_0_gen = model.sample(x_t=x_T, T=0, N=reverse_N, to_numpy=True, sf_alpha=h)\n",
    "\n",
    "    js, kl, wd = evaluate_2d(true_data=x_0.detach().numpy(), fake_data=x_0_gen, x0=x0, x1=x1, y0=y0, y1=y1)\n",
    "\n",
    "    print(f\"h={h:.2f}: js={js:.4f}, kl={kl:.4f}, wd={wd:.4f}\")\n",
    "\n",
    "    data.append([h, js, kl, wd])\n",
    "\n",
    "data = np.array(data)\n",
    "\n",
    "visualize_line(data=data[:, 1], yscale=\"log\", xaxis=data[:, 0], xl=r\"$\\mathsf{h}$\", yl=\"Error\", title=\"Error measured with JS divergence\", savename=None)\n",
    "visualize_line(data=data[:, 2], yscale=\"log\", xaxis=data[:, 0], xl=r\"$\\mathsf{h}$\", yl=\"Error\", title=\"Error measured with KL divergence\", savename=None)\n",
    "visualize_line(data=data[:, 3], yscale=\"log\", xaxis=data[:, 0], xl=r\"$\\mathsf{h}$\", yl=\"Error\", title=\"Error measured with Wasserstein distance\", savename=None)\n",
    "\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.10.4 64-bit ('lyx': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2e4d09e0e1042f9d6170ee46281c29a7b4d25e9af00a6888b49dfa8664f6331e"
   }
  },
  "interpreter": {
   "hash": "65bc9aa1b599357718151687f0a27e5383fabe33cf2a5883e6ad968c33abc6a8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}